{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start out by building a simple CNN to see how the foundations work, then we'll look into improving our methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the Keras library which provides us with the backbone of our neural network, including methods we will use for the process. Learn more about Keras here https://keras.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will import the methods to use to build the CNN. Let's start with Sequential, this will be used to initialize our model for adding layers later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaking of layers, why don't we bring them in right now. Here are the 'learning' layers we will use, and just to recap what they are:\n",
    "\n",
    "Conv2D is our convolutional layer, which will apply the covolutional process of producing the dot product of our input image matrix with a submatrix of the same image which we define. We will add an activation to this process too in order to make this linear process more non-linear.\n",
    "\n",
    "MaxPooling2D will get the most important(max) weights from our convolved process and 'pool' them together into a smaller matrix.\n",
    "\n",
    "Dropout will give some pooled data a probability of 'dropping out' a.k.a not being included into the next layer. This is key in preventing the network from overfitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classify layers will combine our learnings into a network, applying the fundamental process of neural networks. These layers include:\n",
    "\n",
    "Flatten will 'flatten' our data from the learning process into a singular vector, which will be the input for the network.\n",
    "\n",
    "Dense will create the network using the flattened data, and will apply an activation to each layer in the neural net.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of our layers, let's define the problem we will work on. Convolutional Neural Networks are typically used for types of data processing involving data that can be parsed in chunks to identify features, like image and audio. In our example, we will be looking at one of the most popular applications of CNNs, the MNIST handwriting database.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Classifying Handwritten Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mnist_example.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be creating a network to read in images like this and assign them a classification of what number they are. Each image is 28x28 pixels, with each pixel corresponding to a greyscale value from 0-255. Our goal is to create a neural network that will work out the features of each image, such as the forks on the number 4 <img src=\"mnist_four_highlight.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network will then use these features to learn how to classify the numbers, and we will be training the network with over 60,000 labeled handwritten numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Getting the data started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's bring in the dataset and some tools to help us manage the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset containing the training and testing sets\n",
    "from keras.datasets import mnist\n",
    "\n",
    "#we will use this to turn some integers into a binary class matrix and convert to one-hot\n",
    "from keras.utils import np_utils, to_categorical\n",
    "\n",
    "#we will use the Adam gradient algorithm, one of the fastest optimizers for CNNs\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "#we will hold data in np arrays\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in the training and testing data. Our training set contains 60,000 images and the testing set contains 10,000 images. Both sets have corresponding labels to their images as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important thing to do before passing in data into the CNN is making sure the data is actually passable. For that reason, we must format our data. Let's start with the images. Currently the images are our training set are in an array of shape (60000, 28, 28), being 60000 samples, each 28 pixels wide and 28 pixels high. Our Keras Conv2D layer expects a sort of 'depth' aspect for our image, and that depth will be our color channel. Colored images typically have 3 color channels,(Red, Green, Blue), but since we are using greyscale images, we will just use 1 channel. Let's define the shape of our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "num_of_training_images = training_images.shape[0]\n",
    "num_of_test_images = test_images.shape[0]\n",
    "num_of_color_channels = 1\n",
    "pixel_width, pixel_height = 28, 28\n",
    "\n",
    "#image shapes\n",
    "training_image_shape = (num_of_training_images, num_of_color_channels, pixel_width, pixel_height)\n",
    "test_image_shape = (num_of_test_images, num_of_color_channels, pixel_width, pixel_height)\n",
    "print(training_image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reshape our image sets and turn the data into a type we can perform numerical operations on. It is always perferable to choose a type with higher precision, so we will go with float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_images = training_images.reshape(training_image_shape).astype('float32')\n",
    "test_images = test_images.reshape(test_image_shape).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data are floats, we can normalize it by dividing by the max possible value in our color channel, 255. This will turn our data into values between 0 and 1 and will enable us to use these precise numbers in evaluating possible features later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_images /= 255\n",
    "test_images /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now prepared our images for the CNN, now we will look at the labels. The labels are a 1D array containing integers 0-9, and it is not very efficient for our neural network to have to categorize all of these different classes when performing operations, so we will 'binarize' the labels using one-hot encoding using the to_categorical method. To learn more about one-hot: https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_labels = to_categorical(training_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now prepared our data for the CNN! Let's now apply it to the actual neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Form the CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model for which we will add layers to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add layers in accordance to the convolution process described earlier\n",
    "1. Convolve the data using a 5x5 convolve window scanning the image, givng 32 output filters with a ReLU activation (ReLU turns negative values to 0, or gets value if positive)\n",
    "2. Pool the maximum convolved values \n",
    "3. Dropout some values, in this case we will drop 1/4th of the units\n",
    "\n",
    "*We set padding to same to keep the length of inputs to outputs for the convolution and pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (5, 5), padding=\"same\", input_shape=(num_of_color_channels, pixel_width, pixel_height), activation='relu'))\n",
    "model.add(MaxPooling2D(padding=\"same\"))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add layers for the classification process described earlier\n",
    "1. Flatten the data to be fed into the neural network\n",
    "2. Set some ReLU to the nodes, and we are outputting 4 times the amount from our convolved process.\n",
    "3. Get the highest probable classification from the final output, which has 10 outputs corresponding to each class 0-9, using softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(128, kernel_initializer=\"normal\", activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile all the layers together. Since our output, like our labels, will categorical we will use the categorical crossentropy function to compute our loss error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get to training! We will train our model using the training data defined earlier. We are training over 60k images so it should take around 2 minutes for the first epoch, aka the number of times the network passes through the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.1520 - acc: 0.9538\n",
      "Epoch 2/9\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.1103 - acc: 0.9661\n",
      "Epoch 3/9\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0906 - acc: 0.9729\n",
      "Epoch 4/9\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0788 - acc: 0.9751\n",
      "Epoch 5/9\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0684 - acc: 0.9787\n",
      "Epoch 6/9\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0614 - acc: 0.9809\n",
      "Epoch 7/9\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0559 - acc: 0.9825\n",
      "Epoch 8/9\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0517 - acc: 0.9829\n",
      "Epoch 9/9\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0473 - acc: 0.98441s - loss: 0.0478 - ETA: 1s - loss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x182ea60ef0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_images, training_labels, epochs=9, batch_size=150, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During our training, you can see that we've received around 87% accuracy with just 1 epoch, giving 10 epochs can increase the accuracy to around 98%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we trained, let's test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 103us/step\n",
      "We got 98.6% accuracy in our testing set.\n",
      "Our error rate was 3.9%.\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "evaluation = model.evaluate(test_images, test_labels, verbose=1)\n",
    "\n",
    "print(\"We got \" + \"{:.1%}\".format(evaluation[1]) + \" accuracy in our testing set.\")\n",
    "print(\"Our error rate was \" + \"{:.1%}\".format(evaluation[0]) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! That is pretty accurate for a CNN with such few layers. Now that you see how these Convolutional Neural Networks work, here is a challenge for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've just looked at the MNIST handwriting database, now let's look at a compartively similar set, the Fashion MNIST database. <img src=\"fashion_mnist.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This set has the same dimensionality as the MNIST handwriting dataset (60000 training images, 10 classes, 10000 test images, 28x28 pixel images etc..) What would happen if you ran this dataset through our CNN? Would you expect a higher or lower classification accuracy than the handwriting set and why? What would you have to change about the CNN to get the results you desire? Go ahead and load fashion_mnist and run it through the network to confirm your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like more review about convoluted neural networks, here are some reference sources I used when building this tutorial:\n",
    "\n",
    "https://www.youtube.com/watch?v=FTr3n7uBIuE&t=2431s Siraj Ravel - Convolutional Neural Networks - The Math of Intelligence\n",
    "http://colah.github.io/posts/2014-07-Conv-Nets-Modular/ Intuitive explanation of CNNs        \n",
    "https://www.kaggle.com/bugraokcu/cnn-with-keras/code A fantastic application of CNN to this problemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
